---
layout: index
title: 컨테이너 환경에서의 AI 서빙엔진 구축기(1)
nav_order: 1
parent: Tech_Study
permalink: /Tech_Study1
---

작성일자: 2023/01/21

# 컨테이너 환경에서의 AI 서빙엔진 구축기(1)


## 들어가며


안녕하세요, 현재 KT에서 자연어처리 엔진 개발 및 유지/보수중인 김태엽입니다.

약 1년간 AI를 직접 활용하는 서비스를 개발하면서, AI 서비스에 필요한 전반적인 아키텍처와 업무 프로세스에 대한 이해를 키울 수 있었습니다. 또한 AI 서비스의 정확도 및 성능 개선을 위한 작업에 대하여 많은 고민을 하였습니다. 이 글에서는 TA 서비스의 전반적인 아키텍쳐를 설명하고 개발 중에 기술적, 비즈니스적으로 고민했던 부분을 공유하려 합니다.



## 서비스 소개

다른 설명에 앞서 개발중인 TA 서비스에 대해 간략히 설명드리겠습니다.

TA(Text Analysis) 서비스는 상담사와 고객 간의 상담 내역을 분석하며 이를 통해 상담사의 업무 효율성을 높이는 것을 목표로 합니다.

서비스 기능 및 설명은 아래와 같습니다.

1. 표제어 변환

   * 상담 내역에 대하여 숫자, 외래어, 특수 문자 등을 가독성이 좋은 형태로 변환합니다.

     ex) "**에스앤피오백** 관련 상품의 수수료가 **영쩜이오 퍼센트** 넘는지 궁금합니다" -> "**S&P500** 관련 상품의 수수료가 **0.25%** 넘는지 궁금합니다"

2. 마스킹 변환

   * 상담 내역 중 개인정보에 대한 마스킹 처리를 진행합니다.

     ex) "전화번호는 **01024394324**이고 계좌번호는 **110-423-5420**이에요" -> "전화번호는 **###**이고 계좌번호는 **###**이에요  "

3. 띄어쓰기 교정

   * 상담 내역(채팅 상담)에 대하여 필요 시 자동 띄여쓰기를 진행합니다.

     ex) "안녕하세요요금제해지때문에 전화했는데요" -> "안녕하세요 요금제 해지 때문에 전화했는데요"

4. 키워드 분석

   * 상담 내역 중 빈도 수가 높은 어휘와 근접 단어를 분석합니다.

     "어제 주문한 상품 반품처리하려고 하는데 배송시작하는데 얼마나 걸릴까요" -> {"주문":1, "근접어":{상품, 반품}.....}

5. 민원키워드 분석
   * 관리자가 등록한 욕설 및 비속어에 대한 빈도수를 분석합니다.

6. 상담내역 요약(개발 중)
   * 상담 내역에 대한 한 줄 요약을 진행합니다.

7. 상담내역 VOC 유형 자동분류

   * 상담 내역에 대한 VOC 유형(상담 카테고리 유형)을 분류합니다.

     ex) "어제 주문한 상품 반품처리하려고 하는데 배송시작하는데 얼마나 걸릴까요" -> "배송>반품문의"



## 전체 시스템 아키텍처

제가 참여한 TA 서비스 외에도 상담 서비스는 시스템 관점에서 크게 **상담AP** , **콜인프라**,**포탈**, **STT**, **API GW**, **TA**  이렇게 총 5개의 컴포넌트로 구성되어 있습니다. 서비스의 흐름 이해를 돕기 위해 어떻게 연동되는지 장표로 간략히 설명하겠습니다.



[자료1]


* 콜인프라는 전화 교환기 연동, 내선번호 라우팅, 녹취 등을 진행합니다. 녹취 스트림은 STT에 웹소켓 프로토콜로 전달합니다.
* STT는 AI엔진을 통해 녹취 파일을 text로 변환한 후 API GW를 통해 상담 AP로 전달합니다.
* API-GW는 STT<->TA, TA<-> 상담AP, STT <->상담AP와 같이 데이터를 전달하는 GW 역할을 수행합니다.
* TA는 STT로부터 온 텍스트 데이터를 분석하고 결과를 API-GW를 통해 상담 AP로 전달합니다.
* 상담 AP는 상담사들이 사용하는 어플리케이션으로 실시간으로 상담사와 고객의 대화가 노출되며, 상담이 종료되면 TA 분석 결과가 전송됩니다. 상담사는 TA에서 전달한 VOC 유형이 맞는지 검토한 후 정답 VOC 유형을 API-GW로 전송합니다.





## TA 시스템 아키텍처

프로젝트 전체적인 측면에서 과업을 크게 두 가지로 나눈다면 "컨테이너화"와 "멀티테넌시화"였습니다.



## 컨테이너화란?

"컨테이너"는 가상화 기술의 하나로 OS레벨의 가상화로 프로세스를 격리시켜 동작하는 방식입니다. 어떤 프로그램을 "컨테이너화"한다는 것은 **특정 프로세스**와 **프로세스의 실행환경**을 다른 프로세스로부터 격리시킨다는 의미로도 해석이 가능합니다.

이런 컨테이너의 **독립성**은 시스템 아키텍처를 설계할 때, 기존의 On-promise 환경에 비해 여러 방면에서 장점을 가지게 됩니다. 시스템이 복잡할수록 서브시스템의 개수가 많아지고 각 서브시스템을 운영하기 위해 다양한 프로그램이 설치됩니다. 서브시스템들이 동일한 프레임워크, 라이브러리를 사용하지만 다른 버전을 요구하는 일이 충분히 일어날 수 있습니다. 이 때 컨테이너화 된다면 환경을 독립적으로 구성함으로써 버전 호환성을 맞출 수 있습니다.

운이 나쁜 경우에는 서버에 물리적인 손상이 가해져서 서비스 전체를 새로운 서버로 이관해야 하는 순간이 올 수도 있습니다. 컨테이너는 프로세스의 실행환경을 그대로 보존하기 때문에 어떤 서버에서 재실행을 하더라도 오류없이 실행이 가능합니다.

또한 시스템 전체를 여러개의 컨테이너로 분리했을 때 시스템 간 결합도가 느슨해지는 장점이 있습니다. 이를 가장 잘 체감할 수 있는 시기는 배포날 입니다. 기능 업데이트나 버그 픽스와 관련된 배포를 하는 날, 모든 개발자가 남을 필요가 없어지고 배포 기능과 연동된 팀만 남아서 연동 테스트를 실행하면 됩니다.

마지막으로 컨테이너는 On-promise 환경에 비해 자원의 확장성이 뛰어납니다. 기존의 서버 환경은 서비스의 규모가 커지면 그 때마다 CPU, memory들을 추가하거나 물리서버를 추가하는 형태로 자원을 확장했습니다. 컨테이너 관리 툴인 쿠버네티스를 활용하면 트래픽량에 따라 컨테이너의 Replicaset을 늘렸다가 줄이는 형태로 물리적 확장 없이도 효율적으로 자원을 관리할 수 있습니다.

이러한 장점 때문에 On-promise 환경에서 일부 사용되던 어플리케이션을 컨테이너화하고 클라우드 환경에 올리는 작업이 우선적으로 진행되었습니다. 컨테이너화에 맞춰 설계된 TA 아키텍처 구조는 아래와 같습니다.

[자료2]

## 멀티테넌시화란?

"멀티테넌시"란 소프트웨어 어플리케이션의 단일 인스턴스가 여러 고객에게 서비스를 제공하는 형태를 의미합니다. 기존에 Kt 내부에서만 사용하던 상담 서비스를 SaaS(Software as A Service) 형태의 구독 서비스로 변경하기 위해서 어플리케이션 레벨에서 "멀티테넌트"에 맞춰 확장할 수 있는 형태로 인프라 설계가 고안되었습니다.

TA 서비스는 고객이 청약을 진행하고 포탈로부터 개통 신청이 요청되었을 때 시작됩니다. 개통 요청을 받으면 TA DB의 모든 테이블에는 해당 고객의 파티션이 생성되고 개통관련 데이터가 저장됩니다. 이 테이블 중에는 테넌트 별로 기능을 커스터마이징 할 수 있는 사전 테이블들이 존재합니다.(사전 테이블에 대해서는 이후 목차에서 설명하겠습니다.) 또한 고객별로 관리될 형태소 분석기(Mecab) 또한 개통 시점에 개별적으로 설치됩니다.

서비스가 진행되고 데이터가 축적되었을 때, 각 고객은 자신만의 데이터를 갖고 VOC 유형 분류모델을 학습하고 이를 서비스에 활용할 수 있습니다. 이렇게 멀티테넌시화된 서비스는 동일 어플리케이션, 동일 DB를 사용하지만 고객별로 기능의 차이를 준다는 특징을 가지고 있습니다. 또한 어플리케이션, DB의 설계와 컨테이너 구조가 맞물려서 지속적으로 확장할 수 있다는 장점을 갖습니다.

[자료3]



## AI엔진만큼 중요한 토큰화에 관하여


다음은 서비스 개발에 활용된 자연어처리 기술 중 "토큰화"에 대하여 간단한 개념 설명과 개발 절차, 그리고 각 기술이 어떻게 활용되었는지 알아보겠습니다.



### 토큰화


AI 모델의 입력값은 숫자로 구성되어 있어야 합니다. 이 때문에 자연어처리 모델과 같이 문자열을 입력값으로 받는 모델은 전처리 과정에서 **문자**를 **숫자**로 변환해야 합니다. 변환을 할 때 코퍼스를 기반으로 입력값을 쪼개는 작업을 **토큰화**라고 합니다.

**코퍼스: 모델이 이해할 수 있는 최소 단위의 문자열로 구성된 사전(ex. "나","_는", "오늘","도","영화","를")

토큰화의 목적은 우리가 얻는 전체 텍스트 데이터를 가장 의미있는 표현들로 나누기 위함입니다. 영어에서의 의미있는 표현의 기준은 해당 표현의 발생 빈도입니다. 하지만 한국어는 단어의 발생빈도 기준으로만 토큰화를 하기에 조금 까다로운 언어입니다. 띄어쓰기에 의해 단어가 잘 구분되는 영어와 달리, 한글은 어절 단위로 띄어쓰기를 하기 때문입니다. 어절은 보통 합성어로 이루어져 있는데, 어절 단위로 코퍼스를 구성한다면 단어의 양이 많아질 뿐 아니라 유사한 의미를 완전히 다른 단어로 인식하기 때문입니다.

예를 들어 **"오늘은 오늘이고 오늘의 할 일은 오늘 해야한다"**라는 문장이 있을 때 어절 기반으로 코퍼스를 구성하면 

["오늘은", "오늘이고","오늘의","할",일은", "오늘", "해야한다"] 와 같이 토큰화가 이루어질 것 입니다. **오늘**이란 단어가 4번 나왔는데 AI는 이 모든 단어가 독립적인 의미를 갖는다고 학습을 합니다.

어절 단위가 아닌 어근 + 접사로 이뤄지는 한국어의 특성상, 한국어 토큰화에는 보통 형태소 단위의 토큰화가 이뤄집니다.

**형태소 - 의미를 가지는 요소로서 더 이상 분석할 수 없는 가장 작은 말의 단위

### MeCab 엔진


MeCab은 C++ 기반으로 개발된 형태소 분석기로 국립국어원의 21세기 세종계획 말뭉치(Corpus)로 학습된 모델입니다. 엔진은 조건부 확률을 기반으로 입력된 한글 시퀀스를 형태소 단위로 분류합니다. 형태소 분석기를 사용하면 일반적으로 우리가 아는 품사 기반으로 문장이 분할되기 때문에 더 의미있는 표현으로 한국어를 토큰화 할 수 있게 됩니다. 

TA 프로젝트에서 Mecab은 "표제어 변환"과 "키워드 분석"을 목적으로 사용되었습니다. 

### 표제어 변환


"표제어 변환"은 숫자의 의미를 가지는 단어를 숫자로 변환하는 문제였습니다. 전화번호, 금액, 나이, 날짜 등의 숫자를 상담사가 읽기 편한 형태로 보여주기 위해 개발되었습니다.

단어 변환을 위해서 **수사**인 품사를 인식하고 이를 지정된 숫자에 매핑하는 작업이 진행되었습니다. 이후 연속된 수사를 처리하는 로직이 진행되었습니다.

### 키워드 분석


"키워드 분석"은 문장 내 품사가 **명사**인 단어의 빈도수를 계산하는 문제였습니다. 해당 원문에서 가장 많이 출현한 명사를 분석 결과로 상담 AP 화면에 전달하였고, 분석 결과는 DB에 저장되어 나중에 포탈 사이트에서 별, 주간별, 월별 키워드 통계 화면에 사용되었습니다.



### MeCab의 한계..


"표제어 변환", "키워드 분석" 기능의 정확도는 MeCab이 얼마나 명확하게 형태소를 분석하냐에 달려있습니다. 하지만 MeCab 학습 당시의 어휘에는 외래어나 각 사업체에서 쓰는 고유 명사를 포함하지 않았습니다. 또한 수사에 대해서도 오분류되는 경우가 많았습니다. MeCab 엔진의 성능 개선을 위해 MeCab 내부의 사전 파일에 단어를 추가/수정하고 재학습할 수 있는 API를 개발하였고 관리자 화면과 연동하였습니다. 이런 방법은 추가할 단어가 너무 많아 비효율적이며 관리자에 의해 어떤 문장이 잘못 분류되는지 지속적인 모니터링이 필요합니다. 하지만 새로운 유형의 형태소 분석기를 개발하고 발전시키기 위해서는 모든 문장의 형태소를 태깅할 수 있는 고급 인력이 필요합니다. 이러한 한계에 부딪히며 한국어 토큰화의 중요성과 어려움을 체감할 수 있었습니다.







