---
layout: index
title: 파이썬 로깅환경 구축기(2)
nav_order: 3
parent: NLP_Project
permalink: /NLP_Project3
---

작성일자: 2023/02/07

## 멀티프로세싱 환경에서의 파이썬 로깅 구축(2)



향후 프로젝트의 중심이 될 웹 어플리케이션을 구축할 때 파일, db, 콘솔로 로그를 저장하거나 출력해야 할 것이다.

파이썬 내장 모듈을 커스터마이징하고 사용하기 위해 로깅 모듈에 대한 조금 더 깊은 이해가 필요했다.

우선 파이썬 로깅 모듈의 특징을 알아보자



### 로거의 특징

파이썬 logging 모듈에서 Logger는 로그를 전달하는 하나의 객체이다.

로거의 특성을 이해하는 것이 로깅 모듈의 동작 방식을 이해하는데 도움이 됐다.

#### 1. Logger는 재사용이 가능하다.

Logger Object는 logging.getLogger(<로거명>)이란 method를 통해 생성된다.

인자값으로 로거의 이름을 명시해주면, 해당 로거는 프로젝트 내의 다른 모듈, 소스코드에서도 재사용이 가능하다.

만약 로거명이 따로 주어지지 않으면 root logger가 자동으로 실행된다.

예시)

```python
# <main.py>
import logging
logger = logging.getLogger("test_log")


#<src.py>
import logging
logger = logging.getLogger("test_log")
root_logger = logging.getLogger()
```

#### 2. Logger는 계층구조를 가진다.

Logger는 root logger를 최상위 계층으로 하고 그 아래로 계층 구조를 가질 수 있다.

계층구조는 getLogger method를 통해 로거 객체를 생성할 때 "(부모 로그명).(자식 로거명)"과 같은 형태로 생성된다.

상위 계층의 로거는 하위 계층의 로거로부터 로그를 전파받고, 이를 제어하지 않을 경우 root Logger까지 전파되어 올라간다.

전파를 막기 위해서는 자식 로거를 설정할 때 로거 객체의 `propagate` attribute 값을 `0` or `False`로 설정해줘야 한다.

자식 로거의 로그 레벨, 핸들러 등이 설정되지 않는 경우, 부모 로거를 그대로 따라가므로 클래스를 상속받는 것처럼 사용할 수 있다.

예시)

```python
<test.py>
import logging

# 부모 로거 생성
parent_logger = logging.getLogger('a')
parent_logger.setLevel(logging.INFO)

#포매터 생성
formatter = logging.Formatter("%(asctime)s - %(name)s - %(levelname)s - %(message)s")

# 파일핸들러 생성
file_handler = logging.FileHandler('test_file.log')
file_handler.setFormatter(formatter)
# 부모 로거 생성
parent_logger.addHandler(file_handler)

#자식 로거 생성
child_logger = logging.getLogger('a.b')
# 스트림 핸들러 생성
stream_handler = logging.StreamHandler()
child_logger.addHandler(stream_handler)
# 자식 로거 출력
child_logger.info('Test Log')
# child_logger.propagate = False
```

결과)

```
root@c2961f4a0b70:/app/src/log# python test.py
Test Log

<test_file.log>
2023-02-07 06:04:00,247 - a.b - INFO - Test Log
```



예시를 통해 부모<-> 자식 로거 간의 전파가 되는 것을 분명하게 알 수 있다.

부모 로거는 FileHandler가 연결되어 있고 자식 로거에는 StreamHandler가 연결되어 있는데, 자식 로거에서 INFO 레벨의 로그를 찍으면 

2개의 핸들러에 동시에 로그가 찍히는 것을 확인할 수 있다. 

만약 주석 처리된 propagate 설정을 추가하면 이렇게 위로 전파되는 것을 막을 수 있다.



아래의 다이어그램을 보면 로그 이벤트가 저장되는 플로우를 좀 더 자세히 관찰할 수 있다.

 <img src="/docs/NLP_Project/image/python_log_arch.png" width="800" height="600">


#### 3. Config를 통해 로거를 쉽게 커스터마이징 할 수 있다.

위에 예시에서는 코드를 통해 핸들러, 포매터를 추가하고 옵션값을 지정했다. 이런 로그 구성을 json 파일 혹은 yaml 파일에 key-value 형태로 구성할 수 있다. 

예시)

```json
{
	"version":1,
	"formatters":{
		"test_format":{
			"format": "%(asctime)s -process[%(process)d] -thread[%(thread)d] -%(name)s - [%(levelname)s]-[%(lineno)d] - %(message)s"
		}
	},
	"handlers":{
		"console_handler":{
			"class":"logging.StreamHandler",
			"level":"INFO",
			"formatter":"test_format",
			"stream": "ext://sys.stdout"
		},
		"file_handler":{
			"class":"logging.FileHandler",
			"level":"DEBUG",
			"formatter":"test_format",
			"filename":"test.log",
			"encoding":"utf-8"
		}
	},
	"root":{
		"level":"DEBUG",
		"handlers":["console_handler","file_handler"]
	},
	"loggers":{
		"my_logger":{
			"level":"INFO",
			"handlers":["console_handler","file_handler"],
			"propagate":False
		}
		}
	}
```

크게는 `formatter` ->  `handlers` -> 커스텀 로거 형태로 내려가면서 입력한다.

loggers 딕셔너리 내에 있는 "my_logger"는 getLogger('my_logger')를 통해 호출할 때 해당 설정에 맞게 생성된다.

```python
import logging
import logging.config
import json
import os

if __name__ == "__main__":
	with open("logging.json",'r')  as f:
		logconfig = json.load(f)
	logging.config.dictConfig(logconfig)

	test_logger = logging.getLogger("my_logger")
	test_logger.ERROR("let me test")
```



#### 4. Handler 클래스를 상속받아 커스터마이징이 가능하다

아직 생성해본 적은 없지만 필요에 따라 handler 클래스를 상속받아 서브 클래스를 생성할 수 있다.



위와 같은 로그의 성격을 이해하고, 전 글에서 작성한 Gunicorn의 작동방식을 이해한 후에 목표하던 Gunicorn 다중 worker로부터 로그를 수집하여 안정적으로 적재할 수 있었다.



### Quehandler와 Listener를 통한 Flask 로그 적재



여러 시행착오가 있었지만.. 결론부터 말하면 여러 워커에서 생성되는 LogRecord를 Queue에 담아놓고 이를 다른 logger에서 파일로 넘겨주면 해결되는 문제였다. 

구현하고 보니 간단했지만, 테스트를 하는 과정에서 Gunicorn 환경에서 떠 있는 웹 어플리케이션과 Queue를 어떻게 연결해야 하는지 감이 안잡혀 어려웠다.



로그 적재를 위한 step을 나누어 설명하려 한다.



#### 1. Quehandler를 포함한 객체 생성

```
queue = multiprocessing.Queue(-1)
h = logging.handlers.QueueHandler(queue)  # Just the one handler needed
logger = logging.getLogger("my_logger")
logger.addHandler(h)
```

QueHandler는 queue에 log record를 적재하는 Handler 객체이다. 로거에 해당 handler를 포함하면 Queue에 로그를 적재한다.  

파이썬 내장 모듈인 multiprocessing에는 서로 다른 프로세스에서 공유가능한 Queue를 제공한다.

모든 워커가 Queue handler 로그를 사용하고 Queue와 연결되기 위해서는 Flask app 객체를 생성하기 전에 해당 코드를 실행해야 한다.



#### 2. QueListener 프로세스 생성

```python
# util.py
def listener_process(queue):
	with open('./logging.json','r') as f:
		lc = json.load(f)
	logging.config.dictConfig(lc)
	l_logger = logging.getLogger("que_listen_logger")
	l_logger.info(f'[{os.getpid()}]: listener 프로세스가 켜졌습니다')
	while True:
		try:
			record = queue.get()
			# l_logger.info(record)  # No level or filter logic applied - just do it!
			l_logger.handle(record)
		except Exception as e:
			l_logger.exception(e, exc_info=True)

```

```python
# main.py
listener = multiprocessing.Process(target=listener_process,
										args=(queue,))
listener.start()
```

 Queue로부터 logRecord를 수집하기 위한 로거가 하나 더 필요하다. Queue Listening 로그는 queue와 연결된 상태로 지속적으로 데이터를 받아 파일 혹은 스트림으로 로그를 출력한다. 로거는 워커가 아닌 별도의 프로세스에 존재해야 하며, gunicorn이 동작하는 동안 계속 떠 있어야 한다.(다른 worker가 죽어도, 당장 출력할 record가 없어도)

listener 프로세스의 실행 또한 Flask 객체를 생성하기 전에 이뤄져야 한다.



#### 3. test api 생성

```python
@app.route("/test", methods=['GET'])
def home():
	logger.info(f"process:[{os.getpid()}] API가 요청되었습니다")

	return jsonify({"message":"Welcome to the Flask API"})
    
```

간단한 api를 생성하고 요청하며 로그의 생성 과정을 관찰하였다. Gunicorn 기동 시 worker 2개로 세팅하고 프로세스 상태를 확인하며 몇가지 인사이트를 찾을 수 있었다.

```bash
UID   PID  PPID  CMD
root  33    8  /usr/local/bin/python /usr/local/bin/gunicorn --bind 0.0.0.0:8000 --workers 2 main:app
root  36    33 /usr/local/bin/python /usr/local/bin/gunicorn --bind 0.0.0.0:8000 --workers 2 main:app
root  37    33 /usr/local/bin/python /usr/local/bin/gunicorn --bind 0.0.0.0:8000 --workers 2 main:app
root  38    36 /usr/local/bin/python /usr/local/bin/gunicorn --bind 0.0.0.0:8000 --workers 2 main:app
root  39    37 /usr/local/bin/python /usr/local/bin/gunicorn --bind 0.0.0.0:8000 --workers 2 main:app
```

왜 worker를 2개 기동했는데 process가 5개가 떴을까?

로그를 확인해보면 그 이유를 알 수 있다.

```
2023-02-08 02:26:38,401 -process[38] -que_listen_logger - [INFO]-[16] - [38]: listener 프로세스가 켜졌습니다
2023-02-08 02:26:38,480 -process[39] -que_listen_logger - [INFO]-[16] - [39]: listener 프로세스가 켜졌습니다
```

마스터 프로세스는 요청이 들어오기 전에 2개의 worker를 fork한다. 이 fork는 linux os에서 process를 fork하는 것과 동일한 방식으로 r마스터 프로세스를 process를 복사하여 별도의 프로세스 2개를 만들게 된다.

현재 5개의 gunicorn 프로세스는 PID를 기준으로 봤을 때 부모<-> 자식 프로세스로 연결되어 있다.

```
Master Process(33)
ㄴWorker Process(36)
	ㄴListener Process 1(38)
ㄴWorker Process(37)
	ㄴListener Process 2(39)
```

분명 worker 2개 -> Queue -> Listener로 연결되는 구조를 생각했는데 각 worker별로 리스너가 떠있다는 걸 알게 됐다.

그럼 Queue도 2개이려나?

리스너가 시작할 때 queue 객체의 메모리 주소를 로그로 찍어보니 2번 나오는걸 확인할 수 있었다.

```python
l_logger.info(f'queue 메모리 주소 {id(queue)}')

process[47] que_listen_logger - [INFO]-[17] - queue 메모리 주소 140373406923856
process[46] que_listen_logger - [INFO]-[17] - queue 메모리 주소 140373406915664
```

각 프로세스 별로 메모리 주소가 다른 걸 볼 수 있었다.

이를 통해 gunicorn의 fork 방식은 어떠한 내부 로직에 의해 웹 어플리케이션 코드에 있는 모든 자원(서브프로세스, 변수, 등등)을 그대로 복사한다는 것을 알게 됐다.

그런데 이런 식으로 queue와 queue listener가 worker별로 있다면.. queue를 이용하기 전과 동일한 구조가 아닌지 의심이 됐다. 만약 데이터 유실이 없이 로그가 잘 적재되더라도 설계한 구조랑은 달라서 다른 방안을 찾아봤다.



#### 4. gunicorn preload 옵션

방법은 gunicorn 커맨드 사용시 preload 옵션을 사용해주는 것이었다.

Gunicorn은 어플리케이션이 시작될 때 master 프로세스가 worker 프로세스를 생성하는데, 각 프로세스를 다른 메모리 공간에 분리시킨다. 이러면 Flask 객체를 실행하기 전에 선언한 변수, import한 라이브러리 등의 리소스가 모두 메모리에 2번 올라가게 된다.

Queue, Listener 프로세스 등이 2번 올라간 것도 이러한 이유 때문이었다. 이를 방지하기 위해서는 preload라는 option을 사용하면 된다.

preload를 사용할 시, 웹 어플리케이션과 관련된 자원은 master 프로세스의 메모리에만 올라가게 되고 worker들이 이를 공유하게 된다.

```bash
UID   PID  PPID  CMD
root  50    8  /usr/local/bin/python /usr/local/bin/gunicorn --bind 0.0.0.0:8000 --workers 2 --preload main:app
root  53    50 /usr/local/bin/python /usr/local/bin/gunicorn --bind 0.0.0.0:8000 --workers 2 --preload main:app
root  54    50 /usr/local/bin/python /usr/local/bin/gunicorn --bind 0.0.0.0:8000 --workers 2 --preload main:app
root  55    50 /usr/local/bin/python /usr/local/bin/gunicorn --bind 0.0.0.0:8000 --workers 2 --preload main:app

<log파일>
process[53] -thread[139719428458304] -que_listen_logger - [INFO]-[16] - [53]: listener 프로세스가 켜졌습니다
```

프로세스를 확인해보면 아까와 다르게 프로세스가 4개만 떴다.

프로세스 내역과 로그 파일을 비교해서 보면 PID 53번이 리스너 프로세스이고 부모 프로세스가 마스터인 50번인 걸 알 수 있다.

```
2023-02-08 04:43:50,653 -process[55] -thread[139719428458304] -my_logger - [INFO]-[42] - process:[55] API가 요청되었습니다
2023-02-08 04:43:51,162 -process[54] -thread[139719428458304] -my_logger - [INFO]-[42] - process:[54] API가 요청되었습니다
```

또한 API를 호출하면 54, 55 워커 프로세스로부터 로그가 잘 쌓이는 것을 확인할 수 있었다.

위의 프로세스를 내가 생각하는 흐름대로 도식화를 시켜보았다.

 <img src="/docs/NLP_Project/image/quehandler_process.png" width="500" height="430">

이렇게 Gunicorn + Flask 환경에서 로그를 안정적으로 적재할 수 있는 기초적인 틀을 만들 수 있었다. 

공부를 하며 파이썬 로그의 특성, 웹 어플리케이션의 동작 방식을 조금 더 자세하게 알 수 있었다.

차후에 Django + Gunicorn으로 웹서버를 구축할 계획인데 이 때  더 많은 공부를 해야겠다. 또한 공부한 걸 베이스로 Kafka, DB로 로그를 전달하는 커스텀 핸들러도 만들 생각이다.





출처


* [gunicorn preloading(영문)](https://www.joelsleppy.com/blog/gunicorn-application-preloading/)

* [파이썬 로깅 쿡북](https://docs.python.org/ko/3/howto/logging-cookbook.html)

* [웹서버 소켓핸들러 로거 예시](https://gist.github.com/vsajip/4b227eeec43817465ca835ca66f75e2b)

* [파이썬 로깅의 모든것]( https://hamait.tistory.com/880)

* [데이터베이스 핸들러 사용]( https://moonuibee.tistory.com/9)

* [파이썬 공식문서 로깅 ](https://docs.python.org/ko/3.7/howto/logging.html)

* [파이썬 공식문서 TimedRotatingHandler](https://docs.python.org/ko/3/library/logging.handlers.html#logging.handlers.TimedRotatingFileHandler)



